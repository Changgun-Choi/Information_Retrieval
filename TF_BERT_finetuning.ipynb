{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "TF BERT_finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3be532558aec4416aa0524dca0808456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_96a4829993b3412684e6f82d7a4d594c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86e1a4967d7e46a48072040839d5e67a",
              "IPY_MODEL_a275d902aa644529907b9a4b663d0350"
            ]
          }
        },
        "96a4829993b3412684e6f82d7a4d594c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86e1a4967d7e46a48072040839d5e67a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_95bf5e0974f048fc89d465de39757bbb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a4d1199d69344d7832c27c617d6ca5a"
          }
        },
        "a275d902aa644529907b9a4b663d0350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a05f84cea1b44d2ab14f884091d5658c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:02&lt;00:00, 89.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e791bb356a004cf4ac5350ea7fce9026"
          }
        },
        "95bf5e0974f048fc89d465de39757bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a4d1199d69344d7832c27c617d6ca5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a05f84cea1b44d2ab14f884091d5658c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e791bb356a004cf4ac5350ea7fce9026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9fd3ae435e274676974c44920d807f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ddfb0d1d43d4fafb6087a0d9b7d4893",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f9b67a41c3d4cb38af17ed6814e5efc",
              "IPY_MODEL_32715573e0df41a2a348a581488ec290"
            ]
          }
        },
        "6ddfb0d1d43d4fafb6087a0d9b7d4893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f9b67a41c3d4cb38af17ed6814e5efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2472f025e76d467b993c6cf8c17da840",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80b5e12761fc4c638c01f3f4f68cc3a4"
          }
        },
        "32715573e0df41a2a348a581488ec290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a387582c936648d28b0ab3ee06e87596",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 36.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00ada326f51a475ca28eef1024e67f7d"
          }
        },
        "2472f025e76d467b993c6cf8c17da840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80b5e12761fc4c638c01f3f4f68cc3a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a387582c936648d28b0ab3ee06e87596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00ada326f51a475ca28eef1024e67f7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f362276816a40aba05413c3d19188be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f90f863d4910407d8750f94983bdf9b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b2cf627b24c54b3d8cdc3390cd9e5a02",
              "IPY_MODEL_5402c92da205481881320ef5e99db524"
            ]
          }
        },
        "f90f863d4910407d8750f94983bdf9b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2cf627b24c54b3d8cdc3390cd9e5a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4d356bbf6aa34491b139d1e78c026536",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dba176730b8349aaaed51a1a85515fff"
          }
        },
        "5402c92da205481881320ef5e99db524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_de611653f7084f98a9608aceabcba8c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 2.34MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bea034c866ae44069590ce1e1b8226fa"
          }
        },
        "4d356bbf6aa34491b139d1e78c026536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dba176730b8349aaaed51a1a85515fff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de611653f7084f98a9608aceabcba8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bea034c866ae44069590ce1e1b8226fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4640bdebe4384b88a1998e1985d8fa49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e34da30841904aa8a2058966187e7826",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7518314dfcff4d35909cf72a67024b4f",
              "IPY_MODEL_48f460cb8f684e0b85fe8c22a193f0a9"
            ]
          }
        },
        "e34da30841904aa8a2058966187e7826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7518314dfcff4d35909cf72a67024b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bf40ddf5188d4f97a973110874213b80",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68a052071c024eebb18e96b21bea213e"
          }
        },
        "48f460cb8f684e0b85fe8c22a193f0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd7aabf4c9b043c8bacf7d314ca31d75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 1.36kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_839f69c8c2ab4a14a2fccf0fabb7d86f"
          }
        },
        "bf40ddf5188d4f97a973110874213b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68a052071c024eebb18e96b21bea213e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd7aabf4c9b043c8bacf7d314ca31d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "839f69c8c2ab4a14a2fccf0fabb7d86f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "004f76061e524e1f9af499f8cce60e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_914c4a2890664949a190c95353c9bee2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_315c782230e4471e9b9d5657dbac6198",
              "IPY_MODEL_1c6e993a3d6b439d8d511dde354c24c9"
            ]
          }
        },
        "914c4a2890664949a190c95353c9bee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "315c782230e4471e9b9d5657dbac6198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cb7252a23e2140a2a6565fbebaa93b77",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 536063208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 536063208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8cf6858bbde4de8b16f635bd5a6f933"
          }
        },
        "1c6e993a3d6b439d8d511dde354c24c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_15382318833b4f9ca3b926b0dc11506d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 536M/536M [00:13&lt;00:00, 39.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5994eb627e774652bfc06a4db3d86e90"
          }
        },
        "cb7252a23e2140a2a6565fbebaa93b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8cf6858bbde4de8b16f635bd5a6f933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15382318833b4f9ca3b926b0dc11506d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5994eb627e774652bfc06a4db3d86e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bb236ad6a3d49339be8215b51539e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d07e22a99e14f43b8ca53932ee567a6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4524a947b6ff40adb4b51802527ed371",
              "IPY_MODEL_a45d57a8aa304d7a8b36191cd45fe1fc"
            ]
          }
        },
        "9d07e22a99e14f43b8ca53932ee567a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4524a947b6ff40adb4b51802527ed371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_99fb81449c6e491387994ba2c1ab822f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0bd20c4c87942b38535279b46982b38"
          }
        },
        "a45d57a8aa304d7a8b36191cd45fe1fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_263703ea571341fd9dff4612ee5d078a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:12&lt;00:00, 44.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8ff9321cdee4d77842c0b826583dd45"
          }
        },
        "99fb81449c6e491387994ba2c1ab822f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0bd20c4c87942b38535279b46982b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "263703ea571341fd9dff4612ee5d078a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8ff9321cdee4d77842c0b826583dd45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "233b34d9dc704422b88bdc0da5027f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0747cd3b8b024a05b1e98b2dead91306",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_64870e45f4b4460cb877352509db0a11",
              "IPY_MODEL_07fec25d8c10458bb19ef98c5919396f"
            ]
          }
        },
        "0747cd3b8b024a05b1e98b2dead91306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64870e45f4b4460cb877352509db0a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_510528ec711e47deac087aeeeba48c30",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 536063208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 536063208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d69e83be44f148e7bd89a892c60ff516"
          }
        },
        "07fec25d8c10458bb19ef98c5919396f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_edcfd1ac22024f2dab80ba184d88c6c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 536M/536M [00:09&lt;00:00, 57.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23296363a12d40a3bac2fc0741c7e6d1"
          }
        },
        "510528ec711e47deac087aeeeba48c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d69e83be44f148e7bd89a892c60ff516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edcfd1ac22024f2dab80ba184d88c6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23296363a12d40a3bac2fc0741c7e6d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtIDGhzFBrdL"
      },
      "source": [
        "Bert-Base-Uncased\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4B2cbPjMVoD"
      },
      "source": [
        "# 1 Pointwise BERT Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YUv5MjzaoW_"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3nd1n5gQ6_3",
        "outputId": "e0c9f106-df81-480b-c88c-66ebcf68e86a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184,
          "referenced_widgets": [
            "3be532558aec4416aa0524dca0808456",
            "96a4829993b3412684e6f82d7a4d594c",
            "86e1a4967d7e46a48072040839d5e67a",
            "a275d902aa644529907b9a4b663d0350",
            "95bf5e0974f048fc89d465de39757bbb",
            "8a4d1199d69344d7832c27c617d6ca5a",
            "a05f84cea1b44d2ab14f884091d5658c",
            "e791bb356a004cf4ac5350ea7fce9026",
            "9fd3ae435e274676974c44920d807f0a",
            "6ddfb0d1d43d4fafb6087a0d9b7d4893",
            "6f9b67a41c3d4cb38af17ed6814e5efc",
            "32715573e0df41a2a348a581488ec290",
            "2472f025e76d467b993c6cf8c17da840",
            "80b5e12761fc4c638c01f3f4f68cc3a4",
            "a387582c936648d28b0ab3ee06e87596",
            "00ada326f51a475ca28eef1024e67f7d",
            "9f362276816a40aba05413c3d19188be",
            "f90f863d4910407d8750f94983bdf9b2",
            "b2cf627b24c54b3d8cdc3390cd9e5a02",
            "5402c92da205481881320ef5e99db524",
            "4d356bbf6aa34491b139d1e78c026536",
            "dba176730b8349aaaed51a1a85515fff",
            "de611653f7084f98a9608aceabcba8c5",
            "bea034c866ae44069590ce1e1b8226fa"
          ]
        },
        "id": "0K5EtPIPzgVP",
        "outputId": "3319bae5-feb9-4b26-bbee-b6b2fe780af6"
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "tokenizer('He is rich')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3be532558aec4416aa0524dca0808456",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fd3ae435e274676974c44920d807f0a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f362276816a40aba05413c3d19188be",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2002, 2003, 4138, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Ziz-9aqyM4"
      },
      "source": [
        "!wget https://msmarco.blob.core.windows.net/msmarcoranking/triples.train.small.tar.gz\n",
        "!tar -xf triples.train.small.tar.gz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwpj3nO2guwW"
      },
      "source": [
        "##\n",
        "TPU = True\n",
        "if TPU:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "else:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptIpEy-8iFgI"
      },
      "source": [
        "def convert_data(data_df):    # Input: tokens(tokens encoded), segments, masks\n",
        "  global tokenizer\n",
        "  tokens, segments, masks, targets = [], [], [] ,[]\n",
        "    \n",
        "  for i in range(len(data_df)):\n",
        "   \n",
        "    targets.append(data_df[\"relevant\"][i])\n",
        "\n",
        "    que = tokenizer.encode(data_df[\"query\"][i])\n",
        "    doc = tokenizer.encode(data_df[\"passage\"][i])\n",
        "        \n",
        "    doc.pop(0) \n",
        "        \n",
        "        # Maximum Seq_len : cutting the length\n",
        "    if len(que+doc) > SEQ_LEN:  #200 \n",
        "      while len(que+doc) != SEQ_LEN:\n",
        "        doc.pop(-1)  # Cut context\n",
        "      doc.pop(-1)\n",
        "      doc.append(102) #[SEP]\n",
        "          \n",
        "        # Segment\n",
        "        # query, passage, padding\n",
        "        # 00000000, 1111111, 0000000\n",
        "    segment = [0]*len(que) + [1]*len(doc) + [0]*(SEQ_LEN-len(que)-len(doc))\n",
        "        \n",
        "        # Masking, Padding\n",
        "    if len(que + doc) <= SEQ_LEN:\n",
        "      mask = [1]*len(que+doc) + [0]*(SEQ_LEN-len(que+doc))\n",
        "    else:\n",
        "      mask = [1]*len(que+doc)   #No mask\n",
        "          \n",
        "    if len(que + doc) <= SEQ_LEN:\n",
        "      while len(que+doc) != SEQ_LEN: #  padding\n",
        "        doc.append(0)  #passage  padding\n",
        "                              \n",
        "    ids = que + doc # padding \n",
        "        \n",
        "    tokens.append(ids) # [ids], [ids], ........\n",
        "    segments.append(segment)\n",
        "    masks.append(mask)\n",
        "        \n",
        "    # make numpy array \n",
        "  tokens = np.array(tokens)\n",
        "  segments = np.array(segments)\n",
        "  masks = np.array(masks)\n",
        "  targets = np.array(targets)\n",
        "\n",
        "  return [tokens, masks, segments], targets\n",
        "\n",
        "def load_data(pandas_dataframe):\n",
        "  data_df = pandas_dataframe\n",
        "  data_df[\"query\"] = data_df[\"query\"].astype(str)     # String\n",
        "  data_df[\"passage\"] = data_df[\"passage\"].astype(str)\n",
        "  data_x, data_y = convert_data(data_df)\n",
        "\n",
        "  return data_x, data_y   # [tokens,masks,segments], targets\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASJB_jI0D3x1"
      },
      "source": [
        "import pandas as pd \n",
        "train_pos = pd.read_csv(\"/content/triples.train.small.tsv\",\n",
        "                    sep = \"\\t\", nrows = 800000, header = None, skiprows = 1, usecols = [0,1])  1600000\n",
        "train_neg = pd.read_csv(\"/content/triples.train.small.tsv\",\n",
        "                    sep = \"\\t\", nrows = 800000, header = None, skiprows = 1, usecols = [0,2]) \n",
        "\n",
        "train_pos.columns = [\"query\", \"passage\"]\n",
        "train_neg.columns = [\"query\", \"passage\"]\n",
        "train_pos[\"relevant\"] = 1 # target label\n",
        "train_neg[\"relevant\"] = 0 \n",
        "\n",
        "#train = train_pos.append(train_neg)   # List adding\n",
        "train = pd.concat([train_pos, train_neg])\n",
        "train.reset_index(inplace=True, drop=True)           # Resetting Index as Concat makes duplicated sets 00 11 22 33 44 \n",
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4r0VYdTD6hA"
      },
      "source": [
        "import numpy as np\n",
        "SEQ_LEN = 200 \n",
        "BATCH_SIZE = 20         # Small for CPU, GPU        \n",
        "EPOCHS=2 \n",
        "LR=1.0e-5\n",
        "\n",
        "train_x, train_y = load_data(train)        # Load Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjU6byHbzDcq"
      },
      "source": [
        "!pip install tensorflow-addons\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "def get_bert_finetuning_model():\n",
        "  \n",
        "  model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "         \n",
        "  token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n",
        "  mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n",
        "  segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n",
        "\n",
        "  bert_outputs = model([token_inputs, mask_inputs, segment_inputs])         # Putting input into Bert\n",
        "\n",
        "  bert_outputs = bert_outputs[1]\n",
        "  classification = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(bert_outputs)  \n",
        "  BertRanking_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], classification)\n",
        "  opt = tfa.optimizers.RectifiedAdam(lr=LR, weight_decay=0.0025, warmup_proportion=0.05)\n",
        "  BertRanking_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])     \n",
        "\n",
        "  return BertRanking_model\n",
        "\n",
        "##########################\n",
        "\n",
        "path = \"gdrive/My Drive/Colab Notebooks/BERT\"\n",
        "if TPU:\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        " \n",
        "  with strategy.scope():\n",
        "    BertRanking_model = get_bert_finetuning_model()   # Using TPU \n",
        "  BertRanking_model.fit(train_x, train_y, epochs=EPOCHS, shuffle=True, batch_size=BATCH_SIZE, validation_split= 0.2) \n",
        "  BertRanking_model.save_weights(path+\"/BERT_new.h5\")\n",
        "\n",
        "  # GPU \n",
        "else:\n",
        "  BertRanking_model = get_bert_finetuning_model()\n",
        "  BertRanking_model.fit(train_x, train_y, epochs=EPOCHS, shuffle=True, batch_size=BATCH_SIZE, validation_split= 0.2)\n",
        "  BertRanking_model.save_weights(path+\"/BERT_new.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1xokf87ikNN"
      },
      "source": [
        "new_model = get_bert_finetuning_model()\n",
        "new_model.load_weights(path+\"/BERT_new.h5\")\n",
        "new_model.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u2c3VD7coRz",
        "outputId": "9afcf3f4-a69d-4d9e-cb65-fe2602e49b86"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 37.9 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znJjUnmfE91F"
      },
      "source": [
        "## Top 50 rank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRnT5jegg3SP",
        "outputId": "5be71ef3-bea0-497b-abfe-00837ee1b753"
      },
      "source": [
        "def get_bert_finetuning_model():\n",
        "  \n",
        "  model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "         \n",
        "  token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n",
        "  mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n",
        "  segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n",
        "\n",
        "  bert_outputs = model([token_inputs, mask_inputs, segment_inputs])         # Putting input into Bert\n",
        "\n",
        "  bert_outputs = bert_outputs[1]\n",
        "  classification = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(bert_outputs)  # input for Sequential \n",
        "  BertRanking_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], classification)\n",
        "  opt = tfa.optimizers.RectifiedAdam(lr=LR, weight_decay=0.0025, warmup_proportion=0.05)\n",
        "  BertRanking_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])    \n",
        "\n",
        "  return BertRanking_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 686kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mf8KwNtS_6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3fe431d-b7d2-4ab9-a6b5-c59840b72e0f"
      },
      "source": [
        "pointwise_model = get_bert_finetuning_model()\n",
        "pointwise_model.load_weights(\"/content/drive/MyDrive/Colab Notebooks/BERT/BERT_new.h5\")   \n",
        "print(\"pointwise_model loaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pointwise_model loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVEI7y8WIcwL"
      },
      "source": [
        "Convert Pointwise data for Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQdrEgvhfGKk"
      },
      "source": [
        "def predict_convert_data(data_df):\n",
        "    global tokenizer\n",
        "    tokens, masks, segments = [], [], []\n",
        "    \n",
        "    for i in range(len(data_df)):\n",
        "        que = tokenizer.encode(data_df.iloc[i,2])\n",
        "        doc = tokenizer.encode(data_df.iloc[i,3])\n",
        "        \n",
        "        doc.pop(0) \n",
        "        # Maximum Seq_len : cutting the length\n",
        "        if len(que+doc) > SEQ_LEN:  #200 \n",
        "          while len(que+doc) != SEQ_LEN:\n",
        "            doc.pop(-1)  # Cut context\n",
        "          doc.pop(-1)\n",
        "          doc.append(102) #[SEP]\n",
        "          \n",
        "        # Segment\n",
        "        # query, passage, padding\n",
        "        # 00000000, 1111111, 0000000\n",
        "        segment = [0]*len(que) + [1]*len(doc) + [0]*(SEQ_LEN-len(que)-len(doc))\n",
        "        \n",
        "        # Masking, Padding\n",
        "        if len(que + doc) <= SEQ_LEN:\n",
        "          mask = [1]*len(que+doc) + [0]*(SEQ_LEN-len(que+doc))\n",
        "        else:\n",
        "          mask = [1]*len(que+doc)   #No mask\n",
        "          \n",
        "        if len(que + doc) <= SEQ_LEN:\n",
        "          while len(que+doc) != SEQ_LEN: #  padding\n",
        "            doc.append(0)  #passage  padding\n",
        "                              \n",
        "        ids = que + doc # padding \n",
        "        \n",
        "        tokens.append(ids) # [ids], [ids], ........\n",
        "        segments.append(segment)\n",
        "        masks.append(mask)\n",
        "    tokens = np.array(tokens)\n",
        "    segments = np.array(segments)\n",
        "    masks = np.array(masks)\n",
        "    \n",
        "\n",
        "    return [tokens, masks, segments]\n",
        "\n",
        "def predict_load_data(pandas_dataframe):\n",
        "    data_df = pandas_dataframe.copy(deep=False)\n",
        "    data_df[\"query\"] = data_df[\"query\"].astype(str).copy(deep=False)     # String\n",
        "    data_df[\"passage\"] = data_df[\"passage\"].astype(str).copy(deep=False)\n",
        "    data_x = predict_convert_data(data_df)\n",
        "    return data_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9Cmp9OYKzkq",
        "outputId": "50afebdb-66e0-4c70-ac84-381c20a90581"
      },
      "source": [
        "import datetime\n",
        "import csv\n",
        "import pandas as pd \n",
        "                                                                         \n",
        "data_all = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/BERT/all_dev3.csv\", nrows = 100000, skiprows = 0,  sep=\"\\t\", header=None)    #sep=\",\"\n",
        "data_all.columns = ['q_id','p_id','query', 'passage']\n",
        "unqiue_ids = data_all.q_id.unique()\n",
        "data_all = data_all.to_numpy()\n",
        "print(unqiue_ids)\n",
        "print(len(unqiue_ids))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    2  1215  1288  1576  2235  2798  2962  4696  4947  5925  6217  6791\n",
            "  7968  8701  8714  8798  8854  9083  9454  9926 10157 10205 10264 10276\n",
            " 10312 11006 11050 11133 11913 12741 12903 13397 14151 14947 14963 15039\n",
            " 15063 15382 15441 15607 16559 16860 17110 17430 17586 17635 17848 17884\n",
            " 18101 18759 18840 19457 19552 19940 20356 20432 20520 20597 20671 21185\n",
            " 21603 21741 21765 21793 21861 21948 22231 22479 22670 22882 23223 23285\n",
            " 24115 24441 24807 24979 25025 25036 25294 25344 25534 25603 26079 26207\n",
            " 26334 26485 26664 26847 27618 27743 27932 28216 28352 28442 29089 29097\n",
            " 29169 29416 29612 29921 30039 30188]\n",
            "102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am6d45DySVbN"
      },
      "source": [
        "def take_third(elem):\n",
        "    return elem[2]\n",
        "\n",
        "def from_data_to_array(data):\n",
        "    data_ma = []\n",
        "    for row in data:                                              \n",
        "        data_ma.append([row[0], row[1], row[2], row[3]])\n",
        "    return data_ma\n",
        "\n",
        "for id in unqiue_ids:\n",
        "    a = datetime.datetime.now()\n",
        "    matrix = []\n",
        "    data_ma = from_data_to_array(data[data[:, 0] == id])  #  First index : query_id\n",
        "    df = pd.DataFrame(data_ma, columns = ['q_id','p_id','query', 'passage'])\n",
        "    train_data = predict_load_data(df)\n",
        "    \n",
        "    preds = pointwise_model.predict(train_data)\n",
        "    #print(preds)\n",
        "    \n",
        "    for i in range(0, len(data_ma)):\n",
        "        matrix.append([data_ma[i][0], data_ma[i][1], np.float32(preds[i])])\n",
        "    matrix = sorted(matrix, key=take_third, reverse=True)\n",
        "    matrix = pd.DataFrame(matrix,columns=['q_id','p_id','score'])\n",
        "    #print(matrix)\n",
        "\n",
        "    matrix.to_csv(\"result{}.csv\".format(id), index = False)\n",
        "\n",
        "! zip pointwise_results.zip *.csv\n",
        "print(\"ZIP done!!!!!\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download('pointwise_results.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eT4im6Z0xzp"
      },
      "source": [
        "upload = files.upload(pointwise_results.zip)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd4SpzWaXY8p"
      },
      "source": [
        "ls -l "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hMXnkSXZvZA"
      },
      "source": [
        "# 2 Pairwise BERT Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3oD2ctHtF-a",
        "outputId": "ec37ce22-6f48-4143-f6df-e9b5cf324f4c"
      },
      "source": [
        "!tar -xzvf \"/content/drive/MyDrive/Colab Notebooks/BERT/triples.train.small.tar.gz\" -C \"/content/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "triples.train.small.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx_7Fd1tGzqG"
      },
      "source": [
        "Duplicate triples data set by changing \"relevant and non-relevant\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj4JAUzz-2HN"
      },
      "source": [
        "import pandas as pd \n",
        "trainpair_pos = pd.read_csv(\"/content/triples.train.small.tsv\", sep = \"\\t\", nrows =300000, header = None, skiprows = 1, usecols = [0,1,2]) \n",
        "trainpair_pos.columns = [\"query\", \"passage_rel\", \"passage_non\"]                 # 500000\n",
        "trainpair_neg = trainpair_pos.copy()          #Copy \n",
        "\n",
        "trainpair_neg = trainpair_neg[[\"query\", \"passage_non\", \"passage_rel\"]]\n",
        "trainpair_neg.columns = [\"query\", \"passage_rel\", \"passage_non\"]          \n",
        "trainpair_pos[\"relevant\"] = 1\n",
        "trainpair_neg[\"relevant\"] = 0\n",
        "\n",
        "trainpair = pd.concat([trainpair_pos, trainpair_neg])\n",
        "trainpair.reset_index(inplace=True, drop=True)   # Resetting Index\n",
        "trainpair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaou1uDVHITK"
      },
      "source": [
        "Pairwise converting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhi24rBsq-9N"
      },
      "source": [
        "def convert_data(data_df):    # Input: tokens(tokens encoded), segments, masks\n",
        "  global tokenizer\n",
        "  tokens, segments, masks, targets = [], [], [] ,[]\n",
        "    \n",
        "  for i in range(len(data_df)):    \n",
        "    targets.append(data_df[\"relevant\"][i])\n",
        "\n",
        "    que = tokenizer.encode(data_df[\"query\"][i])\n",
        "    doc_1 = tokenizer.encode(data_df[\"passage_rel\"][i])\n",
        "    doc_2 = tokenizer.encode(data_df[\"passage_non\"][i])\n",
        "        \n",
        "    doc_1.pop(0) \n",
        "    doc_2.pop(0) \n",
        "        \n",
        "        # Maximum Seq_len : cutting the length\n",
        "    if len(que+doc_1+doc_2) > SEQ_LEN:  #512\n",
        "      while len(que+doc_1+doc_2) != SEQ_LEN:\n",
        "        doc_2.pop(-1)   \n",
        "      doc_2.pop(-1)\n",
        "      doc_2.append(102) \n",
        "          \n",
        "    # 1) Segment\n",
        "    # query, passage, padding\n",
        "    # 00000 11111 222222 000000\n",
        "    segment = [0]*len(que) + [1]*len(doc_1) + [2]*len(doc_2) + [0]*(SEQ_LEN-len(que)-len(doc_1)-len(doc_2))\n",
        "        \n",
        "    # 2) Masking\n",
        "    if len(que + doc_1 + doc_2) <= SEQ_LEN:\n",
        "      mask = [1]*len(que+doc_1+doc_2) + [0]*(SEQ_LEN-len(que)-len(doc_1)-len(doc_2))       \n",
        "    else:\n",
        "      mask = [1]*len(que+doc_1+doc_2)   #No mask\n",
        "\n",
        "    # 3) Padding for Token Embedding      \n",
        "    if len(que + doc_1 + doc_2) <= SEQ_LEN:\n",
        "      while len(que + doc_1 + doc_2) != SEQ_LEN: \n",
        "        doc_2.append(0)  #passage_non padding\n",
        "                              \n",
        "    ids = que + doc_1 + doc_2 # padding \n",
        "        \n",
        "    tokens.append(ids) # [ids], [ids], \n",
        "    segments.append(segment)\n",
        "    masks.append(mask)\n",
        "        \n",
        "    # make numpy array \n",
        "  tokens = np.array(tokens)\n",
        "  segments = np.array(segments)\n",
        "  masks = np.array(masks)\n",
        "  targets = np.array(targets)\n",
        "  return [tokens, masks, segments], targets\n",
        "\n",
        "def load_data(pandas_dataframe):\n",
        "  data_df = pandas_dataframe\n",
        "  data_df[\"query\"] = data_df[\"query\"].astype(str)     # String\n",
        "  data_df[\"passage_rel\"] = data_df[\"passage_rel\"].astype(str)\n",
        "  data_df[\"passage_non\"] = data_df[\"passage_non\"].astype(str)\n",
        "  data_x, data_y = convert_data(data_df)\n",
        "  return data_x, data_y   # [tokens, masks, segments], targets  = (X. Y)\n",
        "\n",
        "train_x, train_y = load_data(trainpair)        # Load Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANimIgn6Hh4j"
      },
      "source": [
        "Pairwise training and save weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4640bdebe4384b88a1998e1985d8fa49",
            "e34da30841904aa8a2058966187e7826",
            "7518314dfcff4d35909cf72a67024b4f",
            "48f460cb8f684e0b85fe8c22a193f0a9",
            "bf40ddf5188d4f97a973110874213b80",
            "68a052071c024eebb18e96b21bea213e",
            "bd7aabf4c9b043c8bacf7d314ca31d75",
            "839f69c8c2ab4a14a2fccf0fabb7d86f",
            "004f76061e524e1f9af499f8cce60e22",
            "914c4a2890664949a190c95353c9bee2",
            "315c782230e4471e9b9d5657dbac6198",
            "1c6e993a3d6b439d8d511dde354c24c9",
            "cb7252a23e2140a2a6565fbebaa93b77",
            "a8cf6858bbde4de8b16f635bd5a6f933",
            "15382318833b4f9ca3b926b0dc11506d",
            "5994eb627e774652bfc06a4db3d86e90"
          ]
        },
        "id": "zJCgri_gDDmQ",
        "outputId": "fbdef948-c06d-4b86-f9ea-84ed0b464339"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/BERT\" \n",
        "\n",
        "if TPU:\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        " \n",
        "  with strategy.scope():\n",
        "    BertRanking_model = get_bert_finetuning_model()   # Using TPU \n",
        "  BertRanking_model.fit(train_x, train_y, epochs=EPOCHS, shuffle=True, batch_size=BATCH_SIZE, validation_split= 0.2) \n",
        "  BertRanking_model.save_weights(path+\"/BERT_pairwise_2.h5\")\n",
        "  print(\"saved\")\n",
        "  # GPU \n",
        "else:\n",
        "  BertRanking_model = get_bert_finetuning_model()\n",
        "  BertRanking_model.fit(train_x, train_y, epochs=EPOCHS, shuffle=True, batch_size=BATCH_SIZE, validation_split= 0.2)\n",
        "  BertRanking_model.save_weights(path+\"/BERT_pairwise_2.h5\")\n",
        "  print(\"saved\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 686kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4640bdebe4384b88a1998e1985d8fa49",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "004f76061e524e1f9af499f8cce60e22",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f14dc078e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f14dc078e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f14dc078e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f14eac5edd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f14eac5edd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f14eac5edd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'IteratorGetNext:0' shape=(None, 512) dtype=int64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 512) dtype=int64>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 512) dtype=int64>, <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'IteratorGetNext:0' shape=(None, 512) dtype=int64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 512) dtype=int64>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 512) dtype=int64>, <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9629"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'IteratorGetNext:0' shape=(None, 512) dtype=int64>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 512) dtype=int64>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 512) dtype=int64>, <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 5535s 113ms/step - loss: 0.0908 - accuracy: 0.9629 - val_loss: 0.0438 - val_accuracy: 0.9839\n",
            "Epoch 2/2\n",
            "48000/48000 [==============================] - 5435s 113ms/step - loss: 0.0308 - accuracy: 0.9880 - val_loss: 0.1199 - val_accuracy: 0.9588\n",
            "saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLuVErr4Rvac"
      },
      "source": [
        "pairwise_model = get_bert_finetuning_model()\n",
        "pairwise_model.load_weights(path+\"/BERT_pairwise.h5\")\n",
        "pairwise_model.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irvtWR252ozF"
      },
      "source": [
        "## Top 50 Re-rank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563,
          "referenced_widgets": [
            "5bb236ad6a3d49339be8215b51539e60",
            "9d07e22a99e14f43b8ca53932ee567a6",
            "4524a947b6ff40adb4b51802527ed371",
            "a45d57a8aa304d7a8b36191cd45fe1fc",
            "99fb81449c6e491387994ba2c1ab822f",
            "e0bd20c4c87942b38535279b46982b38",
            "263703ea571341fd9dff4612ee5d078a",
            "f8ff9321cdee4d77842c0b826583dd45",
            "233b34d9dc704422b88bdc0da5027f17",
            "0747cd3b8b024a05b1e98b2dead91306",
            "64870e45f4b4460cb877352509db0a11",
            "07fec25d8c10458bb19ef98c5919396f",
            "510528ec711e47deac087aeeeba48c30",
            "d69e83be44f148e7bd89a892c60ff516",
            "edcfd1ac22024f2dab80ba184d88c6c4",
            "23296363a12d40a3bac2fc0741c7e6d1"
          ]
        },
        "id": "7xdZC4BJASd_",
        "outputId": "3223e13c-8387-4a14-cc86-4c397507eec5"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/BERT\" \n",
        "pairwise_model = get_bert_finetuning_model()\n",
        "pairwise_model.load_weights(path+\"/BERT_pairwise.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bb236ad6a3d49339be8215b51539e60",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "233b34d9dc704422b88bdc0da5027f17",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f06c8c13e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f06c8c13e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f06f44c3dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f06f44c3dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYdd_14JLW4H",
        "outputId": "1c777109-2860-4631-92fd-dc7f91e59255"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/BERT/all_dev3.csv\", nrows = 1000, skiprows = 0,  sep=\"\\t\", header=None)    #sep=\",\"\n",
        "data.columns = ['q_id','p_id','query', 'passage']\n",
        "unqiue_ids = data.q_id.unique()\n",
        "all_dev = data.to_numpy()\n",
        "all_dev\n",
        "#print(unqiue_ids)\n",
        "#print(len(unqiue_ids))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 2700543, ' Androgen receptor define',\n",
              "        'Structure-function of the glucagon receptor family of G protein-coupled receptors: the glucagon, GIP, GLP-1, and GLP-2 receptors. Receptor Channels. 2002, 8 (3â€“4): 179â€“188.'],\n",
              "       [2, 2726978, ' Androgen receptor define',\n",
              "        'In pharmacology, an antagonist binds to the receptor cells and blocks or suppresses the normal response of the receptors. Thus, it is easy to see that while an agonist drug initiates a response from the body, an antagonist blocks the normal response of the cell receptor. An antagonist prevents a reaction.n pharmacology, an antagonist binds to the receptor cells and blocks or suppresses the normal response of the receptors. Thus, it is easy to see that while an agonist drug initiates a response from the body, an antagonist blocks the normal response of the cell receptor. An antagonist prevents a reaction.'],\n",
              "       [2, 2726974, ' Androgen receptor define',\n",
              "        'A drug antagonist is any drug that binds with a specific chemical receptor within the body, and in doing so, precludes another drug from binding to such a receptor and therefore stops the original drug from having an affect on the body. drug antagonist is any drug that binds with a specific chemical receptor within the body, and in doing so, precludes another drug from binding to such a receptor and therefore stops the original drug from having an affect on the body.'],\n",
              "       ...,\n",
              "       [2, 8210091, ' Androgen receptor define',\n",
              "        'There are receptor sites on many cells of our body called acetylcholine (ACh) receptor sites (called that because thereâ€™s a neurotransmitter called acetylcholine (ACh)). When ACh attaches to the receptor site protein, it activates it. Youâ€™ll notice it says it activates a G-protein.'],\n",
              "       [2, 2797400, ' Androgen receptor define',\n",
              "        'The activity of receptors can also be regulated by the binding of a ligand to other sites on the receptor, as in allosteric binding sites. Antagonists mediate their effects through receptor interactions by preventing agonist-induced responses.'],\n",
              "       [2, 3877141, ' Androgen receptor define',\n",
              "        'Efficacy spectrum of receptor ligands. An agonist is a chemical that binds to a receptor and activates the receptor to produce a biological response. Whereas an agonist causes an action, an antagonist blocks the action of the agonist and an inverse agonist causes an action opposite to that of the agonist.ypes of agonists [edit]. Receptors can be activated by either endogenous (such as hormones and neurotransmitters) or exogenous (such as drugs) agonists, resulting in a biological response.']],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GetRlrTBIUw-"
      },
      "source": [
        "Convert Pairwise data for Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM5wjJeUADVb"
      },
      "source": [
        "def convert_data(data_df):    # Input: tokens(tokens encoded), segments, masks\n",
        "  global tokenizer\n",
        "  tokens, segments, masks = [], [], []\n",
        "    \n",
        "  for i in range(len(data_df)):    \n",
        "    que = tokenizer.encode(data_df[\"query\"][i])\n",
        "    doc_1 = tokenizer.encode(data_df[\"passage_rel\"][i])\n",
        "    doc_2 = tokenizer.encode(data_df[\"passage_non\"][i])\n",
        "        \n",
        "    doc_1.pop(0)\n",
        "    doc_2.pop(0) \n",
        "        \n",
        "        # Maximum Seq_len : cutting the length\n",
        "    if len(que+doc_1+doc_2) > SEQ_LEN:  #512\n",
        "      while len(que+doc_1+doc_2) != SEQ_LEN:\n",
        "        doc_2.pop(-1)  \n",
        "      doc_2.pop(-1)\n",
        "      doc_2.append(102) #[SEP]\n",
        "          \n",
        "    # 1) Segment\n",
        "    # query, passage, padding\n",
        "    # 00000 11111 222222 000000\n",
        "    segment = [0]*len(que) + [1]*len(doc_1) + [2]*len(doc_2) + [0]*(SEQ_LEN-len(que)-len(doc_1)-len(doc_2))\n",
        "        \n",
        "    # 2) Masking\n",
        "    if len(que + doc_1 + doc_2) <= SEQ_LEN:\n",
        "      mask = [1]*len(que+doc_1+doc_2) + [0]*(SEQ_LEN-len(que)-len(doc_1)-len(doc_2))       \n",
        "    else:\n",
        "      mask = [1]*len(que+doc_1+doc_2)   #No mask\n",
        "\n",
        "    # 3) Padding for Token Embedding      \n",
        "    if len(que + doc_1 + doc_2) <= SEQ_LEN:\n",
        "      while len(que + doc_1 + doc_2) != SEQ_LEN: \n",
        "        doc_2.append(0)  #passage_non padding\n",
        "                              \n",
        "    ids = que + doc_1 + doc_2 # padding \n",
        "        \n",
        "    tokens.append(ids) # [ids], [ids], ........\n",
        "    segments.append(segment)\n",
        "    masks.append(mask)\n",
        "        \n",
        "    # make numpy array \n",
        "  tokens = np.array(tokens)\n",
        "  segments = np.array(segments)\n",
        "  masks = np.array(masks)\n",
        "  return [tokens, masks, segments]\n",
        "\n",
        "def predict_load_data_pair(pandas_dataframe):\n",
        "  data_df = pandas_dataframe.copy(deep=False)\n",
        "  data_df[\"query\"] = data_df[\"query\"].astype(str).copy(deep=False)     # String\n",
        "  data_df[\"passage_rel\"] = data_df[\"passage_rel\"].astype(str).copy(deep=False)\n",
        "  data_df[\"passage_non\"] = data_df[\"passage_non\"].astype(str).copy(deep=False)\n",
        "  data_x= convert_data(data_df)\n",
        "\n",
        "  return data_x  # [tokens, masks, segments], targets  = (X. Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUxeygaZIx4e"
      },
      "source": [
        "Use Top 50 ranking result from Pointwise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Man6G88NQX2"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/BERT/pointwise_results.zip\" -d \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIIpBsE3FpiL",
        "outputId": "407580b9-a05b-458a-a454-01cb1363735b"
      },
      "source": [
        "for i in unqiue_ids:                                          # 50 * 49\n",
        "  data = pd.read_csv(\"/content/result{}.csv\".format(i), nrows = 50, skiprows = 1,  sep=\",\", header=None)    #sep=\",\"  \n",
        "  data = data.to_numpy()\n",
        "  top_50 = []        \n",
        "  for row in data:\n",
        "    #print(row[])                                       \n",
        "    top_50.append([row[0], row[1], all_dev[all_dev[:, 0] == row[0], 2][0], all_dev[all_dev[:, 1] == row[1], 3]])\n",
        "    #print(top_50)\n",
        "    #print(top_50)\n",
        "  df = pd.DataFrame(top_50, columns = [\"q_id\", \"p_id\", \"query\", \"passage\"])\n",
        "  query = df[\"query\"][0]\n",
        "  #q_id =  df[\"q_id\"][0]\n",
        "  p_id =  df[\"p_id\"]\n",
        "  #print(p_id)\n",
        "\n",
        "  score_pairwise_sum = []\n",
        "  for p1 in df[\"passage\"]:   \n",
        "    probas_pairwise = [] # one proba for each p1 - p2 combination \n",
        "    pairwise_pair = []\n",
        "    \n",
        "    for p2 in df[\"passage\"]: # 49\n",
        "        \n",
        "        if p1 == p2:\n",
        "          pass # only compare to the k-1 different passages\n",
        "        else:  # apply model - get proba that p1 is more relevant than p2\n",
        "          pairwise_pair.append([query, p1, p2])\n",
        "          \n",
        "    df_pair = pd.DataFrame(pairwise_pair, columns = [\"query\", \"passage_rel\", \"passage_non\"])\n",
        "    pd.set_option('display.max_rows', 10)\n",
        "        \n",
        "    train_data = predict_load_data_pair(df_pair)\n",
        "    preds = pairwise_model.predict(train_data)\n",
        "    score = float(sum(preds))\n",
        "    #print(score)\n",
        "    score_pairwise_sum.append(score)\n",
        "\n",
        "  df[\"score\"] = score_pairwise_sum\n",
        "  df_pair_score = df[[\"q_id\", \"p_id\", \"score\"]].copy()\n",
        "  df_pair_score = df_pair_score.sort_values(by = \"score\", ascending = False)\n",
        "  df_pair_score.to_csv(\"result{}.csv\".format(i), index = False)\n",
        "  print(\"Saved\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     4339068\n",
            "1      378374\n",
            "2     1001873\n",
            "3     6920058\n",
            "4     7579825\n",
            "       ...   \n",
            "45    6196668\n",
            "46    2066157\n",
            "47    6681590\n",
            "48    1001876\n",
            "49    2948035\n",
            "Name: p_id, Length: 50, dtype: int64\n",
            "Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCBAYOpd7H8M"
      },
      "source": [
        "! zip pairwise_results.zip *.csv\n",
        "print(\"ZIP done!!!!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "_0QPfKbsSFRS",
        "outputId": "1f4c914c-fa6c-4676-c9d1-fd3640efa51b"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('pairwise_results.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b04348ab-d392-4a21-9ec0-e085237a243a\", \"pairwise_results.zip\", 797618)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}